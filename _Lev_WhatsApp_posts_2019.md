<html>
<body>
<p>Lev Selector - WhatsApp messages, 2019</p>
=================================================<br/>
2019-12-04<br/>
David Makovoz, a Lead Data Scientist at TCS.com <br/>
and a good friend of mine has sent me the <br/>
“Gartner's Hype Cycle For AI, 2019”: <br/>
<br/>
&nbsp;- <a href="https://www.forbes.com/sites/louiscolumbus/2019/09/25/whats-new-in-gartners-hype-cycle-for-ai-2019/#7fb8774c547b" target="_blank">https://www.forbes.com/sites/louiscolumbus/2019/09/25/whats-new-in-gartners-hype-cycle-for-ai-2019/#7fb8774c547b</a><br/>
<br/>
Here is the main graph:<br/>
&nbsp;- <img src="https://blogs-images.forbes.com/louiscolumbus/files/2019/09/Gartner-Hype-Cycle-For-Artificial-Intelligence-2019.jpg"><br/>
<br/>
Speech Recognition is predicted to deliver the most <br/>
significant transformational benefits of all technologies <br/>
on the Hype Cycle. <br/>
<br/>
Some other technologies to consider:<br/>
  - AI Cloud Services<br/>
  - AutoML<br/>
  - Augmented Intelligence<br/>
  - Explainable AI<br/>
  - Edge AI<br/>
  - Reinforcement Learning<br/>
  - Quantum Computing<br/>
  - AI Marketplaces<br/>
<br/>
=================================================<br/>
2019-12-01<br/>
 <br/>
Very interesting way to use Neural Network <br/>
to speed up complex calculations. <br/>
 <br/>
A physical viscoelastic earthquake model <br/>
takes long time to compute. <br/>
 <br/>
Scientists trained a simple fully-connected <br/>
neural network to do the same calculations <br/>
500 times faster ! <br/>
 <br/>
Only ~ 100 lines of python code <br/>
(Theano & TensorFlow). <br/>
<br/>
&nbsp;- <a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2017GL072716" target="_blank">https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2017GL072716</a><br/>
<br/>

=================================================<br/>
2019-11-19<br/>
This is a more detailed lecture by Andrej Karpathy at <br/>
ICML (The International Conference on Machine Learning) <br/>
in June 2019. Tesla's auto-pilot is a great real <br/>
example of AI in production.<br/>
<br/>
&nbsp;- <a href="https://slideslive.com/38917690/multitask-learning-in-the-wilderness" target="_blank">https://slideslive.com/38917690/multitask-learning-in-the-wilderness</a><br/>
<br/>
=================================================<br/>
2019-11-16<br/>
PyTorch at Tesla - Andrej Karpathy<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=oBklltKXtDE" target="_blank">https://www.youtube.com/watch?v=oBklltKXtDE</a><br/>
<br/>
=================================================<br/>
2019-11-13<br/>
I often say that learning Machine Learning and AI <br/>
boils down to learning ~ 100 new words.<br/>
<br/>
So finally I have put together a sort-off dictionary.<br/>
It is split into two files.<br/>
<br/>
Please review.<br/>
Let me know if I have missed something worth including there.<br/>
<br/>
&nbsp;- <a href="https://github.com/lselector/ml\_ai\_doc/blob/master/\_dict\_ML\_AI.txt" target="_blank">https://github.com/lselector/ml\_ai\_doc/blob/master/\_dict\_ML\_AI.txt</a>&nbsp;<br/>
<br/>
&nbsp;- <a href="https://github.com/lselector/ml\_ai\_doc/blob/master/\_dict\_Math.txt" target="_blank">https://github.com/lselector/ml\_ai\_doc/blob/master/\_dict\_Math.txt</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-11-08<br/>
Compute used in AI:<br/>
1959 - 2012  - 2y doubling (Moore's law)<br/>
2012-present - 3.4 month doubling<br/>
<br/>
&nbsp;- <a href="https://openai.com/blog/ai-and-compute/#addendum" target="_blank">https://openai.com/blog/ai-and-compute/#addendum</a>&nbsp;<br/><br/>
=================================================<br/>
2019-11-06<br/>
<br/>
Linear regression model has two parameters.<br/>
Standard Convolutional Neural Networks have 10-100 Mln parameters.<br/>
The GPT-2 has 1.5 Bln parameters:<br/>
<br/>
&nbsp;- <a href="https://openai.com/blog/gpt-2-1-5b-release/" target="_blank">https://openai.com/blog/gpt-2-1-5b-release/</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-10-31<br/>
Tom Siebel Apr 8, 2019 at Carnegie Mellon.<br/>
Very good and insightful keynote.<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=4Ie4gat6idQ" target="_blank">https://www.youtube.com/watch?v=4Ie4gat6idQ</a>&nbsp;<br/>
<br/>
Tom Siebel, Sept 23, 2019 at Berkely Engineering<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=EQJrYkSLafU" target="_blank">https://www.youtube.com/watch?v=EQJrYkSLafU</a>&nbsp;<br/>
<br/>
Basically same content as before, but I want to<br/>
highlight two short segments:<br/>
<br/>
time 43:30 - 46:30<br/>
   How C3.ai pays to educate its employees<br/>
<br/>
time 49:00 - 51:40<br/>
   Italy - 14 regions, 14 models<br/>
<br/>
=================================================<br/>
2019-10-29<br/>
Today's note is about Tom Siebel and his companies.<br/>
<br/>
Tom Siebel was employee #20 at Oracle, <br/>
then in 1993 he started his own <br/>
Company “Siebel Systems”, <br/>
which he sold back to Oracle in 2016<br/>
for \$5.85 Bln. <br/>
<br/>Then in 2009 he started “C3 Energy”<br/>
(Carbon-3, where 3 comes from Measure-Mitigate-Monetize), <br/>
which he restructured in 2011 into “C3 IoT” (Internet of Things), <br/>
and in 2016 into C3.ai.<br/>
Today C3.ai is evaluated at \$2+ Bln - and growing fast.<br/>
<br/>
In his last book “Digital Transformation" <br/>
he writes that AI and related technologies<br/>
are disruptive - a life extinction event<br/>
for corporations (similar to ice age for dinosaurs).<br/>
He states that since 2000, 52 percent <br/>
of Fortune 500 companies have fallen off the list.<br/>
<br/>
So in order to survive, organizations <br/>
must undergo digital transformation <br/>
by using elastic cloud computing, <br/>
big data, artificial intelligence, <br/>
and internet of things. <br/>
The book provides a 10-point <br/>
CEO action plan.<br/>
<br/>
Watch this short interview (~ 1 year old):<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=3Eipoa5wYzk" target="_blank">https://www.youtube.com/watch?v=3Eipoa5wYzk</a>&nbsp;<br/>
<br/>
Also this full keynote Apr 8, 2019 at Carnegie Mellon:<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=4Ie4gat6idQ" target="_blank">https://www.youtube.com/watch?v=4Ie4gat6idQ</a>&nbsp;<br/>
=================================================<br/>
2019-10-23<br/>
<br/>
If you are a Data Scientist, you must have heard about H2O.ai.<br/>
This company was developing tools for Machine Learning since 2011.<br/>
Approx. 250,000 users from 18,000 companies are using them.<br/>
These are THE tools you want to use.<br/>
<br/>
H2O tools are free for academic research. <br/>
And most of them are open source.<br/>
There are also commercial tools, like “H2O Driverless AI”:<br/>
&nbsp;- <a href="https://www.h2o.ai/products/h2o-driverless-ai/" target="_blank">https://www.h2o.ai/products/h2o-driverless-ai/</a>&nbsp;<br/>
<br/>
Yesterday, October 22nd I have attended H2OWORLD.<br/>
It is a big annual event in New York City.<br/>
See the list of 60+ speakers and the agenda here:<br/>
&nbsp;- <a href="https://www.h2o.ai/h2oworldnewyork/" target="_blank">https://www.h2o.ai/h2oworldnewyork/</a>&nbsp;<br/>
<br/>
The main announcement was the H2O “Q”.<br/>
&nbsp;- <a href="https://www.h2o.ai/h2o-q/" target="_blank">https://www.h2o.ai/h2o-q/</a>&nbsp;<br/>
<br/>
Another announcements was that Driverless AI<br/>
is now available as SaaS on cloud:<br/>
&nbsp;- <a href="http://docs.h2o.ai/puddle/userguide/\_build/html/index.html" target="_blank">http://docs.h2o.ai/puddle/userguide/\_build/html/index.html</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-10-12<br/>
<br/>
I recommend to subscribe to “The Batch”<br/>
<br/>
&nbsp;- <a href="https://www.deeplearning.ai/thebatch/" target="_blank">https://www.deeplearning.ai/thebatch/</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-10-08<br/>
<br/>
DeepMind Shows How Expensive the AI-Race Is &amp; Google's Strategy
to Win It<br/>
<br/>
&nbsp;- <a href="https://link.medium.com/7hxPE3ZtC0" target="_blank">https://link.medium.com/7hxPE3ZtC0</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-09-30<br/>
<br/>
Survivor Bias in World War 2<br/>
<br/>
It is dangerous to use data "as is" to create a model,<br/>
because the data may be biased to start with,<br/>
and it can easily lead to creating a biased model<br/>
<br/>
Problem occur when we have:<br/>
&nbsp;- under-represented features (missing data)<br/>
&nbsp;- over-represented features,<br/>
&nbsp;- "target leakage" effect.<br/>
<br/>
Survivorship bias:<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=B3YQJ5DwTzM" target="_blank">https://www.youtube.com/watch?v=B3YQJ5DwTzM</a>&nbsp;<br/>
<br/>
Gender Bias:<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=p60-Jdq754A" target="_blank">https://www.youtube.com/watch?v=p60-Jdq754A</a>&nbsp;<br/>
<br/>
Bias in criminal justice:<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=Gi4YeRqfb24" target="_blank">https://www.youtube.com/watch?v=Gi4YeRqfb24</a>&nbsp;<br/>
<br/>
Target Leakage:<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=y8qaI5mpJeA" target="_blank">https://www.youtube.com/watch?v=y8qaI5mpJeA</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-09-22<br/>
Moore's Law animation<br/>
<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=7uvUiq\_jTLM" target="_blank">https://www.youtube.com/watch?v=7uvUiq\_jTLM</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-09-14<br/>
<br/>
Amazing twenty minutes of wisdom from Andrew Ng. <br/>
Number of AI jobs increased 35-times in last two years. <br/>
Exponential growth of number of AI teams and companies. <br/>
Main areas of growth of AI, Andrew’s own focus.<br/>
<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=j2nGxw8sKYU" target="_blank">https://www.youtube.com/watch?v=j2nGxw8sKYU</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-08-28<br/>
Sending a short 4-page PDF explaining common<br/>
terms used to describe model quality - ROC curve, <br/>
Precision, Recall, Accuracy, Confusion Matrix,<br/>
AUC and F1 score. Enjoy!<br/>
=================================================<br/>
2019-08-22<br/>
&nbsp;- <a href="https://techcrunch.com/2019/08/19/the-five-technical-challenges-cerebras-overcame-in-building-the-first-trillion-transistor-chip/" target="_blank">https://techcrunch.com/2019/08/19/the-five-technical-challenges-cerebras-overcame-in-building-the-first-trillion-transistor-chip/</a>&nbsp;<br/>
<br/>
1.2 Trillion transistors as compared with records <br/>
of 20 Bln on the market. Huge jump!! <br/>
400,000 processing cores , <br/>
15 Kwatts of power (difficult to cool it). Wow!<br/>
<br/>
Deep learning is profoundly computationally intensive. <br/>
A recent report by OpenAI showed that,<br/>
between 2012 and 2018, the compute used to train <br/>
the largest models increased by 300,000X.<br/>
<br/>
In other words, AI computing is growing <br/>
at a rate that is 25,000X faster than Moore’s law <br/>
at its peak. <br/>
<br/>
AI compute demand is doubling every 3.5 months.<br/>
<br/>
The Cerebras Wafer Scale Engine (WSE) <br/>
is more than 56X larger than the largest<br/>
graphics processing unit, <br/>
containing 3,000X more on chip memory <br/>
and more than 10,000X the memory bandwidth.<br/>
=================================================<br/>
2019-08-14<br/>
The short video above explains what is Euler's number "e" <br/>
in a very effective and entertaining manner<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=pg827uDPFqA" target="_blank">https://www.youtube.com/watch?v=pg827uDPFqA</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-08-05<br/>
Evolving Generative Adversarial Networks.<br/>
<br/>
Elegant idea. Standard GAN uses just one generator. <br/>
But here they use multiple generators, do natural selection, <br/>
then create new generators as variation of winners. <br/>
This is Darwin’s evolution in action!<br/>
<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=ni6P5KU3SDU" target="_blank">https://www.youtube.com/watch?v=ni6P5KU3SDU</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-08-03<br/>
<br/>
I highly recommend to subscribe to Abundance Insider. <br/>
You will be receiving one email per week - very good information.<br/>
<br/>
&nbsp;- <a href="https://www.diamandis.com/blog/abundance-insider-aug-3-2019" target="_blank">https://www.diamandis.com/blog/abundance-insider-aug-3-2019</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-07-30<br/>
Automatic Machine Learning<br/>
Nice explanation, especially at time mark 7:30 <br/>
where Siraj starts talking about specific AutoML frameworks.<br/>
<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=jn-22XyKsgo" target="_blank">https://www.youtube.com/watch?v=jn-22XyKsgo</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-07-21<br/>
Bidirectional learning. Same network can be used <br/>
as classifier (discriminator) in one direction, <br/>
and as generator (similar to GAN) in back-direction. <br/>
Result - state-of-the-art accuracy on adversarial <br/>
examples of hand-written digits<br/>
<br/>
&nbsp;- <a href="https://arxiv.org/pdf/1805.08006.pdf" target="_blank">https://arxiv.org/pdf/1805.08006.pdf</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-07-18<br/>
Elon Musk's Neuralink presentation<br/>
&nbsp;- <a href="http://youtu.be/lA77zsJ31nA" target="_blank">http://youtu.be/lA77zsJ31nA</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-06-30<br/>
Demo of H2O Driverles<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=wcyMBRRLmqs" target="_blank">https://www.youtube.com/watch?v=wcyMBRRLmqs</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-06-24<br/>
Above is my 8-page PPT about Ensemble Learning, Random Forest and
Boosting. Enjoy.<br/>
<br/>
=================================================<br/>
2019-06-21<br/>
Warner Music signed an algorithm to a record deal<br/>
&nbsp;- <a href="https://www.theverge.com/2019/3/27/18283084/warner-music-algorithm-signed-ambient-music-endel" target="_blank">https://www.theverge.com/2019/3/27/18283084/warner-music-algorithm-signed-ambient-music-endel</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-06-20<br/>
Google Translatotron - translates between languages <br/>
and voices without converting to text:<br/>
<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=38ZXwJj6j8k" target="_blank">https://www.youtube.com/watch?v=38ZXwJj6j8k</a>&nbsp;<br/>
<br/>
Attention in Neural Networks - with examples:<br/>
<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=W2rWgXJBZhU" target="_blank">https://www.youtube.com/watch?v=W2rWgXJBZhU</a>&nbsp;<br/>
=================================================<br/>
2019-06-11<br/>
Nice - lots of common concepts explained in one lecture.<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=a07iwuDWhys" target="_blank">https://www.youtube.com/watch?v=a07iwuDWhys</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-06-03<br/>
Living Portraits - AI brings Mona Lisa to life:<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=P2uZF-5F1wI" target="_blank">https://www.youtube.com/watch?v=P2uZF-5F1wI</a>&nbsp;<br/>
<br/>
See more examples here (Dostoyevskiy, Einstein, Mona Lisa, etc.):<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=p1b5aiTrGzY" target="_blank">https://www.youtube.com/watch?v=p1b5aiTrGzY</a>&nbsp;<br/>
<br/>
Read:<br/>
&nbsp;- <a href="https://www.smithsonianmag.com/smart-news/mona-lisa-comes-life-computer-generated-living-portrait-180972296/" target="_blank">https://www.smithsonianmag.com/smart-news/mona-lisa-comes-life-computer-generated-living-portrait-180972296/</a>&nbsp;<br/>
&nbsp;- <a href="https://arxiv.org/abs/1905.08233v1" target="_blank">https://arxiv.org/abs/1905.08233v1</a>&nbsp;<br/>
=================================================<br/>
2019-06-02<br/>
Very interesting work on creating interpretable models.<br/>
Cynthia Rudin's latest paper was just published<br/>
in Nature - and exploded all&nbsp; over twitter:<br/>
&nbsp;- <a href="https://www.nature.com/articles/s42256-019-0048-x" target="_blank">https://www.nature.com/articles/s42256-019-0048-x</a>&nbsp;<br/>
&nbsp;- <a href="https://arxiv.org/abs/1811.10154" target="_blank">https://arxiv.org/abs/1811.10154</a>&nbsp;<br/>
&nbsp;- <a href="https://arxiv.org/pdf/1811.10154" target="_blank">https://arxiv.org/pdf/1811.10154</a>&nbsp;<br/>
<br/>
You can listen to here in these videos:<br/>
&nbsp; New Algorithms for Interpretable Machine Learning<br/>
&nbsp;&nbsp;&nbsp;- <a href="https://www.youtube.com/watch?v=FsLP-kkvIIw" target="_blank">https://www.youtube.com/watch?v=FsLP-kkvIIw</a>&nbsp;<br/>
&nbsp; Secrecy, Criminal Justice, and Variable Importance<br/>
&nbsp;&nbsp;&nbsp;- <a href="https://www.youtube.com/watch?v=KAatZNd-7LM" target="_blank">https://www.youtube.com/watch?v=KAatZNd-7LM</a>&nbsp;<br/>
&nbsp; QA<br/>
&nbsp;&nbsp;&nbsp;- <a href="https://www.youtube.com/watch?v=p4DTrcK6tLs" target="_blank">https://www.youtube.com/watch?v=p4DTrcK6tLs</a>&nbsp;<br/>
=================================================<br/>
2019-05-31<br/>
Look at figure 1 in this article.<br/>
Using massive compute power at Google researches <br/>
has found optimized architectures which provide <br/>
great quality of predictions with much smaller <br/>
numbers of nodes in the model !!<br/>
<br/>
&nbsp;- <a href="https://arxiv.org/pdf/1905.11946.pdf" target="_blank">https://arxiv.org/pdf/1905.11946.pdf</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-05-29<br/>
This short video is 3.5 years old - still excellent <br/>
explanation of why we need multiple layers in <br/>
Neural Networks<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=He4t7Zekob0" target="_blank">https://www.youtube.com/watch?v=He4t7Zekob0</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-05-22<br/>
Robot trains to throw objects into a box in real <br/>
physical world and in simulation. <br/>
I guess soon we will have professional basketball <br/>
players-robots ?<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=JJlSgm9OByM" target="_blank">https://www.youtube.com/watch?v=JJlSgm9OByM</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-05-18<br/>
This is an amazing treat to listen to Ken Thompson,<br/>
the original creator of Unix. Today Unix is everywhere. <br/>
Linux, Cloud, mobile phones and tablets. <br/>
Even Microsoft is now adopting unix. <br/>
I know this lecture is not related to ML &amp; AI, <br/>
but this is just such a gem to listen <br/>
"from the horses mouth" about first days, <br/>
a must-watch for any computer engineer.<br/>
<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=EY6q5dv\_B-o" target="_blank">https://www.youtube.com/watch?v=EY6q5dv\_B-o</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-05-15<br/>
12 things I wish I’d known before starting as a Data Scientist<br/>
&nbsp;- <a href="https://link.medium.com/vEanNBN7HW" target="_blank">https://link.medium.com/vEanNBN7HW</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-04-28<br/>
Tesla plans to provide taxi services at 1/10th of <br/>
the price of Uber or Lyft. And Tesla car owners <br/>
will be able to let their car to work as a taxi <br/>
and earn ~\$30K/year, \$300K over car's lifetime. <br/>
Musk said: "The fundamental message that <br/>
consumers should be taking today is that <br/>
it is financially insane to buy anything <br/>
other than a Tesla".<br/>
<br/>
&nbsp;- <a href="https://www.businessinsider.com/tesla-takes-direct-aim-uber-lyft-with-robotaxi-plan-2019-4" target="_blank">https://www.businessinsider.com/tesla-takes-direct-aim-uber-lyft-with-robotaxi-plan-2019-4</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-04-27<br/>
Natural Language Processing - short video from Siraj (March 2019)<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=bDxFvr1gpSU" target="_blank">https://www.youtube.com/watch?v=bDxFvr1gpSU</a>&nbsp;<br/>
<br/>
Siraj talks about different language models<br/>
(terms like Seq2Seq, Attention, Transformer, BERT).<br/>
<br/>
Here is a good textual explanation by Maxime Allard:<br/>
&nbsp;- <a href="https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04" target="_blank">https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04</a>&nbsp;<br/>
<br/>
And here are two "classical" papers to know:<br/>
<br/>
(2017) Attention Is All You Need<br/>
&nbsp;- <a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank">https://arxiv.org/pdf/1706.03762.pdf</a>&nbsp;<br/>
<br/>
(2018) BERT: Pre-training of Deep Bidirectional Transformers for
Language Understanding<br/>
&nbsp;- <a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank">https://arxiv.org/pdf/1810.04805.pdf</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-04-21<br/>
This is not about ML&amp;AI, but it is amazing.<br/>
A working heart can now be 3D-printed from <br/>
patient's own cells !<br/>
<br/>
"Israeli scientists print 3D heart with human <br/>
tissue and vessels":<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=qe0hgBdk7V8" target="_blank">https://www.youtube.com/watch?v=qe0hgBdk7V8</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-04-17<br/>
Great video from Siraj - How AI will look in 2040 ?!<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=mvwBgAqrheo" target="_blank">https://www.youtube.com/watch?v=mvwBgAqrheo</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-04-10<br/>
Very good thinking from Andrew Ng - watch 10 min <br/>
of this video starting at 40 min 15 sec timestamp <br/>
until 50 min 15 sec<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=qnDlFTYnbR0" target="_blank">https://www.youtube.com/watch?v=qnDlFTYnbR0</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-04-08<br/>
Here is a gallery of images generated by modern <br/>
GANs (Generative Adversarial Network). <br/>
&nbsp;- <a href="https://thispersondoesnotexist.com/" target="_blank">https://thispersondoesnotexist.com/</a>&nbsp;<br/>
<br/>
Click on image - and a small popup will show <br/>
on the right-bottom. There is a link there <br/>
"Click for another person" - you can click <br/>
multiple times. Amazing quality.<br/>
<br/>
=================================================<br/>
2019-04-08<br/>
Imagine that it is possible to use 3D-printer <br/>
to print pre-trained Neural Network. <br/>
It then can perform very fast <br/>
and use very low power to operate.<br/>
&nbsp;- <a href="https://www.photonics.com/Articles/UCLA\_Researchers\_Create\_All-Optical\_Diffractive/a63751" target="_blank">https://www.photonics.com/Articles/UCLA\_Researchers\_Create\_All-Optical\_Diffractive/a63751</a>&nbsp;<br/>
<br/>
&nbsp;- <a href="https://twimlai.com/twiml-talk-237-deep-learning-in-optics-with-aydogan-ozcan/" target="_blank">https://twimlai.com/twiml-talk-237-deep-learning-in-optics-with-aydogan-ozcan/</a>&nbsp;<br/>
<br/>
&nbsp;- <a href="https://arxiv.org/pdf/1804.08711.pdf" target="_blank">https://arxiv.org/pdf/1804.08711.pdf</a>&nbsp;<br/>
<br/>
Some nice pictures showing the set-up and real <br/>
classifier (for hand-written digits)<br/>
<br/>
=================================================<br/>
2019-03-31<br/>
<br/>
Topic: BIAS-VARIANCE TRADE-OFF.<br/>
<br/>
Model\_Error = Bias + Vairance + Noise<br/>
<br/>
Bias:<br/>
Model is too simple.<br/>
For example, model is straight line.<br/>
Model doesn't fit data closely.<br/>
Adding data doesn't help.<br/>
Training longer doesn't help.<br/>
Problem is with the model not fitting data.<br/>
<br/>
Vairance:<br/>
Variance happens when algorithm tries <br/>
to fit training data too well.<br/>
It matches training data very well (over-fitting),<br/>
but error on test data set doesn't decrease.<br/>
In fact, error on test data can increase.<br/>
<br/>
Noise:<br/>
Data will always have noise from sample to sample.<br/>
<br/>
Look at pictures here:<br/>
<br/>
&nbsp;- <a href="https://www.quora.com/What-is-the-best-way-to-explain-the-bias-variance-trade-off-in-layman%E2%80%99s-terms" target="_blank">https://www.quora.com/What-is-the-best-way-to-explain-the-bias-variance-trade-off-in-layman%E2%80%99s-terms</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-03-25<br/>
Random Forest (RF) - a simple classification method.<br/>
<br/>
Idea:<br/>
<br/>
Instead of one decision tree create a "forest" of trees.<br/>
(typically 100-200 or more trees).<br/>
<br/>
Each tree is trained separately using a random<br/>
subset of data and features.<br/>
<br/>
The data and features for each tree are randomly selected<br/>
using common "Bootstrap Sampling" technique<br/>
(which simply means - select randomly with replacement)<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=tTZybQTE0dw" target="_blank">https://www.youtube.com/watch?v=tTZybQTE0dw</a>&nbsp;<br/>
<br/>
Once 100 trees are trained on random samples,<br/>
this "Random Forest" of decision trees<br/>
can be used to make classification decisions<br/>
by voting (aggregating, averaging).<br/>
<br/>
RF is example of an "Ensemble" method.<br/>
RF is example of "Bagging" method.<br/>
Bagging means "Bootstrap Sampling + Aggregating"<br/>
<br/>
RF is doing democratic voting.<br/>
It is averaging.<br/>
Thus it is good at removing variance in decisions.<br/>
It makes decisions more stable, removes overfitting.<br/>
<br/>
But unfortunately RF can not remove bias.<br/>
If individual decisions are biased in the same way,<br/>
the average will be also biased the same way.<br/>
RF does not remove bias.<br/>
<br/>
There is another ensemble technique called "Boosting"<br/>
which is designed to remove bias.<br/>
Boosting is done step-by-step sequentially.<br/>
Thus boosting methods are usually slower than Bagging.<br/>
Typical example of boosting method is XGBoost.<br/>
<br/>
It is interesting to think of a system of government<br/>
which would use "Boosting" instead of democratic "Bagging". <br/>
<br/>
=================================================<br/>
2019-03-20<br/>
DeepMasterPrints<br/>
&nbsp;- <a href="https://arxiv.org/pdf/1705.07386.pdf" target="_blank">https://arxiv.org/pdf/1705.07386.pdf</a>&nbsp;<br/>
<br/>
Authors have created a way to open ~70% of fingerprint protected devices.<br/>
They basically created a method to create an artificial fingerprint<br/>
which can be used as a master key.<br/>
This is amazing.<br/>
They used Generative Adversarial Network methodology.<br/>
<br/>
=================================================<br/>
2019-03-18<br/>
Things to know in ML &amp; AI<br/>
<br/>
linear regression<br/>
&nbsp; (fit points with a straight line)<br/>
<br/>
ML classification:<br/>
&nbsp;- logistic regression<br/>
&nbsp;- Random Forest<br/>
&nbsp;- XGBoost<br/>
&nbsp;- Naive Bayes<br/>
&nbsp;- SVM (Support Vector Machine)<br/>
&nbsp;- KNN (K-Nearest Neighbors)<br/>
&nbsp;- K-means<br/>
&nbsp;- gaussian mixture model clustering<br/>
<br/>
Neural Networks<br/>
&nbsp;&nbsp;&nbsp; MLP = Multi-Level Perceptron<br/>
&nbsp;&nbsp;&nbsp; CNN = Convolutional Neural Network<br/>
&nbsp;&nbsp;&nbsp; ResNet - State of the art CNN<br/>
&nbsp;&nbsp;&nbsp; U-Net &amp; Image segmentation<br/>
&nbsp;&nbsp;&nbsp; RNN = Recurrent Neural Network<br/>
&nbsp;&nbsp;&nbsp; LSTM &amp; GRU<br/>
&nbsp;&nbsp;&nbsp; GAN = Generative Adversarial Network<br/>
&nbsp;&nbsp;&nbsp; Variational Auto-Encoder<br/>
&nbsp;&nbsp;&nbsp; etc.<br/>
&nbsp;&nbsp;&nbsp; etc.<br/>
<br/>
Reinforcement Learning<br/>
&nbsp; (games, robotics, self-driving cars, etc.)<br/>
<br/>
Then, of course, standard terms like:<br/>
&nbsp;- underfitting, overfitting<br/>
&nbsp;- regularization<br/>
&nbsp;- training set, validation &amp; test sets<br/>
&nbsp;- cross-validation folding<br/>
&nbsp;- confusion matrix<br/>
&nbsp;- ROC curve<br/>
&nbsp;- Precision &amp; Recall<br/>
&nbsp;- cross-entropy and KL-divergence<br/>
&nbsp;- NLP (Natural Language Processing)<br/>
&nbsp;- tf-idf, sentiment, intent<br/>
&nbsp;- word2vec<br/>
&nbsp;- hidden layers, latent factors<br/>
&nbsp;- explainability, bags of words/features<br/>
&nbsp;- Monte-Carlo<br/>
&nbsp;- Numenta<br/>
&nbsp;- PCA<br/>
&nbsp;- Propensity Score Matching<br/>
&nbsp;- linear discriminant analysis<br/>
&nbsp;- Topic Modeling<br/>
&nbsp;- Restricted Boltzman Machine<br/>
&nbsp;- Recommender Systems, Collaborative filtering<br/>
&nbsp;- Google translate, Attention Mechanism<br/>
&nbsp;- etc.<br/>
&nbsp;- etc.<br/>
<br/>
&nbsp;The lists above cover some common terms<br/>
&nbsp;well known to any Data Scientist today.<br/>
<br/>
&nbsp;This WhatsApp distribution list is not a<br/>
&nbsp;systematic tutorial.<br/>
&nbsp;But over time we will cover many of these topics.<br/>
<br/>
For example, here is a 4-min video explaining<br/>
Random Forest classification:<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=LIPtRVDmj1M" target="_blank">https://www.youtube.com/watch?v=LIPtRVDmj1M</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-03-17<br/>
Hello, sending a 4-page PDF file explaining the term "Bayes",
"Bayesian", etc.<br/>
<br/>
=================================================<br/>
2019-03-13<br/>
Geoff Hinton<br/>
&nbsp;- <a href="http://youtu.be/l9RWTMNnvi4" target="_blank">http://youtu.be/l9RWTMNnvi4</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-03-11<br/>
How neural networks learn<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=pFWiauHOFpY" target="_blank">https://www.youtube.com/watch?v=pFWiauHOFpY</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-03-09<br/>
bags of features, explain-ability<br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=QpptSohzuDo" target="_blank">https://www.youtube.com/watch?v=QpptSohzuDo</a>&nbsp;<br/>
<br/>
=================================================<br/>
2019-03-05<br/>
Augmenting dataset <br/>
&nbsp;- <a href="https://www.youtube.com/watch?v=YFL-MI5xzgg" target="_blank">https://www.youtube.com/watch?v=YFL-MI5xzgg</a>&nbsp;<br/>
<br/>
=================================================<br/>
=================================================<br/>
=================================================<br/>
</body>
</html>
